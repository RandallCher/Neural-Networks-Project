{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mohamedelhakim/Transformer-CNN-Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hybrid model combines a Convolutional Neural Network (CNN) and a Transformer to classify ECG signals. The CNN first extracts local features from the input signal, capturing patterns like peaks and troughs. The output of the CNN is then passed to a Transformer, which processes these features to capture long-range dependencies, learning relationships between distant points in the signal. This approach leverages the strengths of both architectures: the CNN’s ability to focus on local patterns and the Transformer’s capacity to understand global context. The final output is a classification of the ECG signal, benefiting from both local and global feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=rnnamp_model['text']\n",
    "# y=np.array(rnnamp_model['labels'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/combined.csv')\n",
    "\n",
    "dataframes = {}\n",
    "directory_path = 'Heartbeat_Dataset'\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        # Remove the .csv extension for the DataFrame name\n",
    "        df_name = os.path.splitext(file)[0]\n",
    "        dataframes[df_name] = pd.read_csv(file_path, header= None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = dataframes['mitbih_train']\n",
    "# train_df = pd.read_csv('./augmented_data/train_data_SMOTE.csv', header=None)\n",
    "val_df = pd.read_csv('./augmented_data/val_data.csv', header=None)\n",
    "train_df = pd.read_csv('./augmented_data/train_data_augment.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "N    166516\n",
      "Q     14703\n",
      "V     13257\n",
      "S      5088\n",
      "F      1479\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_15764\\110624464.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0         N\n",
      "1         N\n",
      "2         N\n",
      "3         N\n",
      "4         N\n",
      "         ..\n",
      "201038    Q\n",
      "201039    V\n",
      "201040    V\n",
      "201041    V\n",
      "201042    N\n",
      "Name: 188, Length: 201043, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_15764\\110624464.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0         N\n",
      "1         N\n",
      "2         Q\n",
      "3         N\n",
      "4         V\n",
      "         ..\n",
      "289880    Q\n",
      "289881    Q\n",
      "289882    Q\n",
      "289883    Q\n",
      "289884    Q\n",
      "Name: 188, Length: 289885, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  val_df.iloc[:, -1] = val_df.iloc[:, -1].replace(labels)\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
    "val_df.iloc[:, -1] = val_df.iloc[:, -1].replace(labels)\n",
    "# Now get the value counts for the renamed last column\n",
    "train_counts = train_df.iloc[:, -1].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.162234</td>\n",
       "      <td>0.292553</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.747340</td>\n",
       "      <td>0.784574</td>\n",
       "      <td>0.779255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.169062</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.465610</td>\n",
       "      <td>0.552539</td>\n",
       "      <td>0.684207</td>\n",
       "      <td>0.779386</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.790620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>0.235267</td>\n",
       "      <td>0.373240</td>\n",
       "      <td>0.452205</td>\n",
       "      <td>0.562973</td>\n",
       "      <td>0.695076</td>\n",
       "      <td>0.737792</td>\n",
       "      <td>0.731643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.974265</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.591912</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.974265</td>\n",
       "      <td>0.902842</td>\n",
       "      <td>0.608593</td>\n",
       "      <td>0.391031</td>\n",
       "      <td>0.144205</td>\n",
       "      <td>0.075705</td>\n",
       "      <td>-0.023077</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.044383</td>\n",
       "      <td>0.069298</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.003257</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201038</th>\n",
       "      <td>201038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892103</td>\n",
       "      <td>0.447464</td>\n",
       "      <td>0.215695</td>\n",
       "      <td>0.087608</td>\n",
       "      <td>0.068994</td>\n",
       "      <td>0.068994</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.068994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201039</th>\n",
       "      <td>201039</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201040</th>\n",
       "      <td>201040</td>\n",
       "      <td>0.880868</td>\n",
       "      <td>1.017543</td>\n",
       "      <td>0.943873</td>\n",
       "      <td>0.881833</td>\n",
       "      <td>0.824386</td>\n",
       "      <td>0.766895</td>\n",
       "      <td>0.742575</td>\n",
       "      <td>0.652308</td>\n",
       "      <td>0.412934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201041</th>\n",
       "      <td>201041</td>\n",
       "      <td>0.905849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963465</td>\n",
       "      <td>0.870365</td>\n",
       "      <td>0.821367</td>\n",
       "      <td>0.755004</td>\n",
       "      <td>0.710117</td>\n",
       "      <td>0.687944</td>\n",
       "      <td>0.550285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201042</th>\n",
       "      <td>201042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899425</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.330460</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201043 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0            0  0.053191  0.162234  0.292553  0.441489  0.521277  0.627660   \n",
       "1            1  0.056398  0.169062  0.323026  0.465610  0.552539  0.684207   \n",
       "2            2  0.039252  0.124614  0.235267  0.373240  0.452205  0.562973   \n",
       "3            3  0.974265  0.867647  0.591912  0.312500  0.128676  0.022059   \n",
       "4            4  0.974265  0.902842  0.608593  0.391031  0.144205  0.075705   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "201038  201038  1.000000  0.892103  0.447464  0.215695  0.087608  0.068994   \n",
       "201039  201039  0.922000  1.000000  0.970000  0.892000  0.850000  0.792000   \n",
       "201040  201040  0.880868  1.017543  0.943873  0.881833  0.824386  0.766895   \n",
       "201041  201041  0.905849  1.000000  0.963465  0.870365  0.821367  0.755004   \n",
       "201042  201042  1.000000  0.899425  0.594828  0.310345  0.146552  0.250000   \n",
       "\n",
       "             7         8         9    ...       179     180       181  \\\n",
       "0       0.747340  0.784574  0.779255  ...  0.000000  0.0000  0.000000   \n",
       "1       0.779386  0.778626  0.790620  ...  0.000000  0.0000  0.000000   \n",
       "2       0.695076  0.737792  0.731643  ...  0.000000  0.0000  0.000000   \n",
       "3       0.000000  0.014706  0.044118  ...  0.000000  0.0000  0.000000   \n",
       "4      -0.023077  0.027176  0.008174  ...  0.047375  0.0618  0.044383   \n",
       "...          ...       ...       ...  ...       ...     ...       ...   \n",
       "201038  0.068994  0.066960  0.068994  ...  0.000000  0.0000  0.000000   \n",
       "201039  0.752000  0.732000  0.604000  ...  0.000000  0.0000  0.000000   \n",
       "201040  0.742575  0.652308  0.412934  ...  0.000000  0.0000  0.000000   \n",
       "201041  0.710117  0.687944  0.550285  ...  0.000000  0.0000  0.000000   \n",
       "201042  0.330460  0.327586  0.416667  ...  0.000000  0.0000  0.000000   \n",
       "\n",
       "             182       183       184       185       186       187  188  \n",
       "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "4       0.069298  0.027665  0.000986 -0.003257  0.002834 -0.001337    N  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "201038  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    Q  \n",
       "201039  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    V  \n",
       "201040  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    V  \n",
       "201041  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    V  \n",
       "201042  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "\n",
       "[201043 rows x 189 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:,:187]\n",
    "y_label = train_df.iloc[:,-1]\n",
    "\n",
    "X_test = val_df.iloc[:,:187]\n",
    "y_label_test = val_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188\n",
       "N    166516\n",
       "Q     14703\n",
       "V     13257\n",
       "S      5088\n",
       "F      1479\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label)\n",
    "num_classes = len(label_encoder.classes_) \n",
    "y_train = np.eye(num_classes)[y] \n",
    "\n",
    "y = label_encoder.fit_transform(y_label_test)\n",
    "y_test = np.eye(num_classes)[y] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=1)  \n",
    "X_test = np.expand_dims(X_test, axis=1)  \n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train).float()  \n",
    "X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_train_tensor = torch.tensor(y_train).long()  \n",
    "y_test_tensor = torch.tensor(y_test).long()   \n",
    "\n",
    "y_train_tensor = y_train_tensor.argmax(dim=1) \n",
    "y_test_tensor = y_test_tensor.argmax(dim=1)\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([201043, 1, 187])\n",
      "y_train_tensor shape: torch.Size([201043])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_tensor shape:\", X_train_tensor.shape) \n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x0000028003C98B90>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000280041E0310>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class CNNTransformerHybrid(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, num_layers, d_model=128):\n",
    "        super(CNNTransformerHybrid, self).__init__()\n",
    "\n",
    "        # CNN Feature extractor with Conv1d\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.projector = nn.Linear(256, d_model)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads), num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 2:\n",
    "            x = x.unsqueeze(1)  \n",
    "\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x)))) \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x)))) \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x)))) \n",
    "\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.projector(x)  \n",
    "\n",
    "        # Transformer encoding\n",
    "        x = x.permute(1, 0, 2) \n",
    "        x = self.encoder(x) \n",
    "\n",
    "\n",
    "        x = x.mean(dim=0) \n",
    "        x = self.fc(self.dropout(x)) \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model instantiation\n",
    "model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5, \n",
    "    num_heads=8,   \n",
    "    num_layers=6,  \n",
    "    d_model=128   \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNTransformerHybrid(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (projector): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Train Loss: 0.6693, Train Accuracy: 0.8282\n",
      "Test Loss: 2.8777, Test Accuracy: 0.2000\n",
      "Epoch 2/25\n",
      "Train Loss: 0.6635, Train Accuracy: 0.8283\n",
      "Test Loss: 2.9423, Test Accuracy: 0.2000\n",
      "Epoch 3/25\n",
      "Train Loss: 0.6618, Train Accuracy: 0.8283\n",
      "Test Loss: 2.9178, Test Accuracy: 0.2000\n",
      "Epoch 4/25\n",
      "Train Loss: 0.6620, Train Accuracy: 0.8283\n",
      "Test Loss: 2.9590, Test Accuracy: 0.2000\n",
      "Epoch 5/25\n",
      "Train Loss: 0.6605, Train Accuracy: 0.8283\n",
      "Test Loss: 2.9185, Test Accuracy: 0.2000\n",
      "Epoch 6/25\n",
      "Train Loss: 0.6605, Train Accuracy: 0.8283\n",
      "Test Loss: 2.9021, Test Accuracy: 0.2000\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5,  \n",
    "    num_heads=8, \n",
    "    num_layers=6  \n",
    ").to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "\n",
    "patience = 5  \n",
    "best_test_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "epochs = 25\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train the model\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    test_loss, test_acc, preds, labels = test(model, test_loader, criterion, device)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        early_stop_counter = 0  \n",
    "\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = min(len(train_accuracies), len(test_accuracies))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), train_accuracies[:num_epochs], label='Training Accuracy')\n",
    "plt.plot(np.arange(num_epochs), test_accuracies[:num_epochs], label='Test Accuracy')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model/cnn_transformer_model_augment.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./model/cnn_transformer_model_augment.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 188)\n"
     ]
    }
   ],
   "source": [
    "test_df = dataframes['mitbih_test']\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "x_data = train_df.iloc[:,:187]\n",
    "y_label = train_df.iloc[:,-1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label.values.ravel())\n",
    "\n",
    "\n",
    "\n",
    "X = x_data\n",
    "X_test = np.expand_dims(X, axis=1)   \n",
    "X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_test_tensor = torch.tensor(y).long()        \n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients during testing\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)         \n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6564, Test Accuracy: 0.8283\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "epoch_loss, epoch_acc, all_preds, all_labels = test(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
