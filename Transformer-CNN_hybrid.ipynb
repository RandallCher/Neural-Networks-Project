{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mohamedelhakim/Transformer-CNN-Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hybrid model combines a Convolutional Neural Network (CNN) and a Transformer to classify ECG signals. The CNN first extracts local features from the input signal, capturing patterns like peaks and troughs. The output of the CNN is then passed to a Transformer, which processes these features to capture long-range dependencies, learning relationships between distant points in the signal. This approach leverages the strengths of both architectures: the CNN’s ability to focus on local patterns and the Transformer’s capacity to understand global context. The final output is a classification of the ECG signal, benefiting from both local and global feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=rnnamp_model['text']\n",
    "# y=np.array(rnnamp_model['labels'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/combined.csv')\n",
    "\n",
    "dataframes = {}\n",
    "directory_path = 'Heartbeat_Dataset'\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        # Remove the .csv extension for the DataFrame name\n",
    "        df_name = os.path.splitext(file)[0]\n",
    "        dataframes[df_name] = pd.read_csv(file_path, header= None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = dataframes['mitbih_train']\n",
    "\n",
    "# train_df = pd.read_csv('./augmented_data/train_data_SMOTE.csv', header=None)\n",
    "train_df = pd.read_csv('./augmented_data/train_data_augment.csv', header=None)\n",
    "\n",
    "val_df = pd.read_csv('./augmented_data/val_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "N    173931\n",
      "Q     15435\n",
      "V     13890\n",
      "S      5334\n",
      "F      1539\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_40816\\1416067443.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0         N\n",
      "1         N\n",
      "2         N\n",
      "3         N\n",
      "4         N\n",
      "         ..\n",
      "210124    N\n",
      "210125    N\n",
      "210126    N\n",
      "210127    N\n",
      "210128    N\n",
      "Name: 188, Length: 210129, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_40816\\1416067443.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0        N\n",
      "1        N\n",
      "2        N\n",
      "3        N\n",
      "4        N\n",
      "        ..\n",
      "17506    N\n",
      "17507    N\n",
      "17508    N\n",
      "17509    N\n",
      "17510    N\n",
      "Name: 188, Length: 17511, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  val_df.iloc[:, -1] = val_df.iloc[:, -1].replace(labels)\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "val_df.iloc[:, -1] = val_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "train_counts = train_df.iloc[:, -1].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.162234</td>\n",
       "      <td>0.292553</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.747340</td>\n",
       "      <td>0.784574</td>\n",
       "      <td>0.779255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.169062</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.465610</td>\n",
       "      <td>0.552539</td>\n",
       "      <td>0.684207</td>\n",
       "      <td>0.779386</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.790620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>0.235267</td>\n",
       "      <td>0.373240</td>\n",
       "      <td>0.452205</td>\n",
       "      <td>0.562973</td>\n",
       "      <td>0.695076</td>\n",
       "      <td>0.737792</td>\n",
       "      <td>0.731643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.974265</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.591912</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.974265</td>\n",
       "      <td>0.902842</td>\n",
       "      <td>0.608593</td>\n",
       "      <td>0.391031</td>\n",
       "      <td>0.144205</td>\n",
       "      <td>0.075705</td>\n",
       "      <td>-0.023077</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.044383</td>\n",
       "      <td>0.069298</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.003257</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210124</th>\n",
       "      <td>210124</td>\n",
       "      <td>0.988635</td>\n",
       "      <td>0.829085</td>\n",
       "      <td>0.225501</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>0.280695</td>\n",
       "      <td>0.338321</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.303065</td>\n",
       "      <td>0.310157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210125</th>\n",
       "      <td>210125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836635</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.030902</td>\n",
       "      <td>0.270558</td>\n",
       "      <td>0.343805</td>\n",
       "      <td>0.316364</td>\n",
       "      <td>0.305684</td>\n",
       "      <td>0.314839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210126</th>\n",
       "      <td>210126</td>\n",
       "      <td>0.968867</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.478207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151930</td>\n",
       "      <td>0.242839</td>\n",
       "      <td>0.173101</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.161893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210127</th>\n",
       "      <td>210127</td>\n",
       "      <td>0.968867</td>\n",
       "      <td>0.969796</td>\n",
       "      <td>0.577795</td>\n",
       "      <td>0.146315</td>\n",
       "      <td>-0.008532</td>\n",
       "      <td>0.263230</td>\n",
       "      <td>0.198243</td>\n",
       "      <td>0.179698</td>\n",
       "      <td>0.146332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>-0.005664</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210128</th>\n",
       "      <td>210128</td>\n",
       "      <td>0.977515</td>\n",
       "      <td>0.936592</td>\n",
       "      <td>0.549750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188873</td>\n",
       "      <td>0.295558</td>\n",
       "      <td>0.214141</td>\n",
       "      <td>0.187379</td>\n",
       "      <td>0.200796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210129 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0            0  0.053191  0.162234  0.292553  0.441489  0.521277  0.627660   \n",
       "1            1  0.056398  0.169062  0.323026  0.465610  0.552539  0.684207   \n",
       "2            2  0.039252  0.124614  0.235267  0.373240  0.452205  0.562973   \n",
       "3            3  0.974265  0.867647  0.591912  0.312500  0.128676  0.022059   \n",
       "4            4  0.974265  0.902842  0.608593  0.391031  0.144205  0.075705   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "210124  210124  0.988635  0.829085  0.225501  0.042213  0.280695  0.338321   \n",
       "210125  210125  1.000000  0.836635  0.256798  0.030902  0.270558  0.343805   \n",
       "210126  210126  0.968867  0.914072  0.478207  0.000000  0.151930  0.242839   \n",
       "210127  210127  0.968867  0.969796  0.577795  0.146315 -0.008532  0.263230   \n",
       "210128  210128  0.977515  0.936592  0.549750  0.000000  0.188873  0.295558   \n",
       "\n",
       "             7         8         9    ...       179       180       181  \\\n",
       "0       0.747340  0.784574  0.779255  ...  0.000000  0.000000  0.000000   \n",
       "1       0.779386  0.778626  0.790620  ...  0.000000  0.000000  0.000000   \n",
       "2       0.695076  0.737792  0.731643  ...  0.000000  0.000000  0.000000   \n",
       "3       0.000000  0.014706  0.044118  ...  0.000000  0.000000  0.000000   \n",
       "4      -0.023077  0.027176  0.008174  ...  0.047375  0.061800  0.044383   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "210124  0.307400  0.303065  0.310157  ...  0.000278 -0.000004 -0.000439   \n",
       "210125  0.316364  0.305684  0.314839  ...  0.000000  0.000000  0.000000   \n",
       "210126  0.173101  0.150685  0.161893  ...  0.000000  0.000000  0.000000   \n",
       "210127  0.198243  0.179698  0.146332  ... -0.000144 -0.001681  0.003404   \n",
       "210128  0.214141  0.187379  0.200796  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "             182       183       184       185       186       187  188  \n",
       "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "4       0.069298  0.027665  0.000986 -0.003257  0.002834 -0.001337    N  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "210124  0.001255 -0.003134  0.000000  0.000000  0.000000  0.000000    N  \n",
       "210125  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "210126  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "210127 -0.004778  0.005584 -0.005664  0.004947 -0.003468  0.001365    N  \n",
       "210128  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    N  \n",
       "\n",
       "[210129 rows x 189 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train_df.iloc[:,:187]\n",
    "# y_label = train_df.iloc[:,-1]\n",
    "\n",
    "X_train = train_df.iloc[:,:187]\n",
    "y_label_train = train_df.iloc[:,-1]\n",
    "\n",
    "X_test = val_df.iloc[:,:187]\n",
    "y_label_test = val_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188\n",
       "N    173931\n",
       "Q     15435\n",
       "V     13890\n",
       "S      5334\n",
       "F      1539\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y_label)\n",
    "# num_classes = len(label_encoder.classes_) \n",
    "# y = np.eye(num_classes)[y] \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label_train)\n",
    "num_classes = len(label_encoder.classes_) \n",
    "y_train = np.eye(num_classes)[y] \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label_test)\n",
    "num_classes = len(label_encoder.classes_) \n",
    "y_test = np.eye(num_classes)[y] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=1)  \n",
    "X_test = np.expand_dims(X_test, axis=1)  \n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train).float()  \n",
    "X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_train_tensor = torch.tensor(y_train).long()  \n",
    "y_test_tensor = torch.tensor(y_test).long()   \n",
    "\n",
    "y_train_tensor = y_train_tensor.argmax(dim=1) \n",
    "y_test_tensor = y_test_tensor.argmax(dim=1)\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([210129, 1, 187])\n",
      "y_train_tensor shape: torch.Size([210129])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_tensor shape:\", X_train_tensor.shape) \n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x0000016C3AC7C510>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000016C3A5CF7D0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class CNNTransformerHybrid(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, num_layers, d_model=128):\n",
    "        super(CNNTransformerHybrid, self).__init__()\n",
    "\n",
    "        # CNN Feature extractor with Conv1d\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.projector = nn.Linear(256, d_model)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads), num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 2:\n",
    "            x = x.unsqueeze(1)  \n",
    "\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x)))) \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x)))) \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x)))) \n",
    "\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.projector(x)  \n",
    "\n",
    "        # Transformer encoding\n",
    "        x = x.permute(1, 0, 2) \n",
    "        x = self.encoder(x) \n",
    "\n",
    "\n",
    "        x = x.mean(dim=0) \n",
    "        x = self.fc(self.dropout(x)) \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model instantiation\n",
    "model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5, \n",
    "    num_heads=8,   \n",
    "    num_layers=6,  \n",
    "    d_model=128   \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNTransformerHybrid(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (projector): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Train Loss: 0.6701, Train Accuracy: 0.8276\n",
      "Test Loss: 0.6583, Test Accuracy: 0.8277\n",
      "Epoch 2/25\n",
      "Train Loss: 0.6646, Train Accuracy: 0.8277\n",
      "Test Loss: 0.6578, Test Accuracy: 0.8277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 83\u001b[0m\n\u001b[0;32m     79\u001b[0m test_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[51], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[49], line 39\u001b[0m, in \u001b[0;36mCNNTransformerHybrid.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Transformer encoding\u001b[39;00m\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m---> 39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)) \n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:906\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m    903\u001b[0m         x\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m    905\u001b[0m     )\n\u001b[1;32m--> 906\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:931\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 931\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5,  \n",
    "    num_heads=8, \n",
    "    num_layers=6  \n",
    ").to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "\n",
    "patience = 5  \n",
    "best_test_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "epochs = 25\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train the model\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    test_loss, test_acc, preds, labels = test(model, test_loader, criterion, device)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        early_stop_counter = 0  \n",
    "\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = min(len(train_accuracies), len(test_accuracies))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), train_accuracies[:num_epochs], label='Training Accuracy')\n",
    "plt.plot(np.arange(num_epochs), test_accuracies[:num_epochs], label='Test Accuracy')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/cnn_transformer_model_augment.pth\"\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "# print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 188)\n"
     ]
    }
   ],
   "source": [
    "test_df = dataframes['mitbih_test']\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "x_data = train_df.iloc[:,:187]\n",
    "y_label = train_df.iloc[:,-1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label.values.ravel())\n",
    "\n",
    "\n",
    "\n",
    "X = x_data\n",
    "X_test = np.expand_dims(X, axis=1)   \n",
    "X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_test_tensor = torch.tensor(y).long()        \n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients during testing\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)         \n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6581, Test Accuracy: 0.8277\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "epoch_loss, epoch_acc, all_preds, all_labels = test(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
