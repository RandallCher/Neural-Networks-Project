{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mohamedelhakim/Transformer-CNN-Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hybrid model combines a Convolutional Neural Network (CNN) and a Transformer to classify ECG signals. The CNN first extracts local features from the input signal, capturing patterns like peaks and troughs. The output of the CNN is then passed to a Transformer, which processes these features to capture long-range dependencies, learning relationships between distant points in the signal. This approach leverages the strengths of both architectures: the CNN’s ability to focus on local patterns and the Transformer’s capacity to understand global context. The final output is a classification of the ECG signal, benefiting from both local and global feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=rnnamp_model['text']\n",
    "# y=np.array(rnnamp_model['labels'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/combined.csv')\n",
    "\n",
    "dataframes = {}\n",
    "directory_path = 'Heartbeat_Dataset'\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        # Remove the .csv extension for the DataFrame name\n",
    "        df_name = os.path.splitext(file)[0]\n",
    "        dataframes[df_name] = pd.read_csv(file_path, header= None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = dataframes['mitbih_train']\n",
    "\n",
    "train_df = pd.read_csv('./augmented_data/smote_dataset.csv', header=None)\n",
    "#train_df = pd.read_csv('./augmented_data/st_dataset.csv', header=None)\n",
    "\n",
    "# val_df = pd.read_csv('./augmented_data/val_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "N    72471\n",
      "S    72471\n",
      "V    72471\n",
      "F    72471\n",
      "Q    72471\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_6576\\233767904.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0         N\n",
      "1         N\n",
      "2         N\n",
      "3         N\n",
      "4         N\n",
      "         ..\n",
      "362350    Q\n",
      "362351    Q\n",
      "362352    Q\n",
      "362353    Q\n",
      "362354    Q\n",
      "Name: 187, Length: 362355, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "# val_df.iloc[:, -1] = val_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "train_counts = train_df.iloc[:, -1].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362350</th>\n",
       "      <td>0.734129</td>\n",
       "      <td>0.616127</td>\n",
       "      <td>0.485778</td>\n",
       "      <td>0.351101</td>\n",
       "      <td>0.190840</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>0.032269</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.031527</td>\n",
       "      <td>0.071370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362351</th>\n",
       "      <td>0.801753</td>\n",
       "      <td>0.541161</td>\n",
       "      <td>0.500729</td>\n",
       "      <td>0.487252</td>\n",
       "      <td>0.461045</td>\n",
       "      <td>0.445255</td>\n",
       "      <td>0.391488</td>\n",
       "      <td>0.333737</td>\n",
       "      <td>0.260162</td>\n",
       "      <td>0.150138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362352</th>\n",
       "      <td>0.973720</td>\n",
       "      <td>0.925187</td>\n",
       "      <td>0.873577</td>\n",
       "      <td>0.801348</td>\n",
       "      <td>0.707915</td>\n",
       "      <td>0.592022</td>\n",
       "      <td>0.471505</td>\n",
       "      <td>0.376119</td>\n",
       "      <td>0.301465</td>\n",
       "      <td>0.228963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362353</th>\n",
       "      <td>0.735002</td>\n",
       "      <td>0.634742</td>\n",
       "      <td>0.531005</td>\n",
       "      <td>0.417347</td>\n",
       "      <td>0.320142</td>\n",
       "      <td>0.193078</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>0.045439</td>\n",
       "      <td>0.044225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362354</th>\n",
       "      <td>0.654426</td>\n",
       "      <td>0.484590</td>\n",
       "      <td>0.459756</td>\n",
       "      <td>0.439790</td>\n",
       "      <td>0.440998</td>\n",
       "      <td>0.418604</td>\n",
       "      <td>0.395626</td>\n",
       "      <td>0.335727</td>\n",
       "      <td>0.296405</td>\n",
       "      <td>0.206284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362355 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1       0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2       1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3       0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4       0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "362350  0.734129  0.616127  0.485778  0.351101  0.190840  0.089054  0.032269   \n",
       "362351  0.801753  0.541161  0.500729  0.487252  0.461045  0.445255  0.391488   \n",
       "362352  0.973720  0.925187  0.873577  0.801348  0.707915  0.592022  0.471505   \n",
       "362353  0.735002  0.634742  0.531005  0.417347  0.320142  0.193078  0.117065   \n",
       "362354  0.654426  0.484590  0.459756  0.439790  0.440998  0.418604  0.395626   \n",
       "\n",
       "             7         8         9    ...  178  179  180  181  182  183  184  \\\n",
       "0       0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1       0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3       0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4       0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...          ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "362350  0.009664  0.031527  0.071370  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "362351  0.333737  0.260162  0.150138  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "362352  0.376119  0.301465  0.228963  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "362353  0.064134  0.045439  0.044225  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "362354  0.335727  0.296405  0.206284  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        185  186  187  \n",
       "0       0.0  0.0    N  \n",
       "1       0.0  0.0    N  \n",
       "2       0.0  0.0    N  \n",
       "3       0.0  0.0    N  \n",
       "4       0.0  0.0    N  \n",
       "...     ...  ...  ...  \n",
       "362350  0.0  0.0    Q  \n",
       "362351  0.0  0.0    Q  \n",
       "362352  0.0  0.0    Q  \n",
       "362353  0.0  0.0    Q  \n",
       "362354  0.0  0.0    Q  \n",
       "\n",
       "[362355 rows x 188 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train_df.iloc[:,:187]\n",
    "# y_label = train_df.iloc[:,-1]\n",
    "\n",
    "X_train = train_df.iloc[:,:187]\n",
    "y_label_train = train_df.iloc[:,-1]\n",
    "\n",
    "# X_test = val_df.iloc[:,:187]\n",
    "# y_label_test = val_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187\n",
       "N    72471\n",
       "S    72471\n",
       "V    72471\n",
       "F    72471\n",
       "Q    72471\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y_label)\n",
    "# num_classes = len(label_encoder.classes_) \n",
    "# y = np.eye(num_classes)[y] \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label_train)\n",
    "num_classes = len(label_encoder.classes_) \n",
    "y_train = np.eye(num_classes)[y] \n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y_label_test)\n",
    "# num_classes = len(label_encoder.classes_) \n",
    "# y_test = np.eye(num_classes)[y] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=1)  \n",
    "# X_test = np.expand_dims(X_test, axis=1)  \n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train).float()  \n",
    "# X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_train_tensor = torch.tensor(y_train).long()  \n",
    "# y_test_tensor = torch.tensor(y_test).long()   \n",
    "\n",
    "y_train_tensor = y_train_tensor.argmax(dim=1) \n",
    "# y_test_tensor = y_test_tensor.argmax(dim=1)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([362355, 1, 187])\n",
      "y_train_tensor shape: torch.Size([362355])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_tensor shape:\", X_train_tensor.shape) \n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x00000294A36A3790>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000294A36A3890>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class CNNTransformerHybrid(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, num_layers, d_model=128):\n",
    "        super(CNNTransformerHybrid, self).__init__()\n",
    "\n",
    "        # CNN Feature extractor with Conv1d\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.projector = nn.Linear(256, d_model)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads), num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 2:\n",
    "            x = x.unsqueeze(1)  \n",
    "\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x)))) \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x)))) \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x)))) \n",
    "\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.projector(x)  \n",
    "\n",
    "        # Transformer encoding\n",
    "        x = x.permute(1, 0, 2) \n",
    "        x = self.encoder(x) \n",
    "\n",
    "\n",
    "        x = x.mean(dim=0) \n",
    "        x = self.fc(self.dropout(x)) \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model instantiation\n",
    "model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5, \n",
    "    num_heads=8,   \n",
    "    num_layers=6,  \n",
    "    d_model=128   \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNTransformerHybrid(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (projector): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [2, 32, 1, 187]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m187\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[15], line 30\u001b[0m, in \u001b[0;36mCNNTransformerHybrid.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m---> 30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))) \n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))) \n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))) \n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1795\u001b[0m     ):\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [2, 32, 1, 187]"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sample_input = torch.randn(32, 1, 187).to(device) \n",
    "model = CNNTransformerHybrid(    \n",
    "    input_dim=187, \n",
    "    num_classes=5, \n",
    "    num_heads=8,   \n",
    "    num_layers=6,  \n",
    "    d_model=128  ).to(device) \n",
    "\n",
    "output = model(sample_input)\n",
    "print(output.shape)\n",
    "\n",
    "# Visualize\n",
    "summary(model, (32, 1, 187))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Train Loss: 0.1877, Train Accuracy: 0.9357\n",
      "Epoch 2/25\n",
      "Train Loss: 0.0803, Train Accuracy: 0.9732\n",
      "Epoch 3/25\n",
      "Train Loss: 0.0556, Train Accuracy: 0.9820\n",
      "Epoch 4/25\n",
      "Train Loss: 0.0429, Train Accuracy: 0.9864\n",
      "Epoch 5/25\n",
      "Train Loss: 0.0348, Train Accuracy: 0.9889\n",
      "Epoch 6/25\n",
      "Train Loss: 0.0299, Train Accuracy: 0.9904\n",
      "Epoch 7/25\n",
      "Train Loss: 0.0256, Train Accuracy: 0.9917\n",
      "Epoch 8/25\n",
      "Train Loss: 0.0228, Train Accuracy: 0.9928\n",
      "Epoch 9/25\n",
      "Train Loss: 0.0207, Train Accuracy: 0.9933\n",
      "Epoch 10/25\n",
      "Train Loss: 0.0180, Train Accuracy: 0.9942\n",
      "Epoch 11/25\n",
      "Train Loss: 0.0168, Train Accuracy: 0.9947\n",
      "Epoch 12/25\n",
      "Train Loss: 0.0156, Train Accuracy: 0.9953\n",
      "Epoch 13/25\n",
      "Train Loss: 0.0150, Train Accuracy: 0.9954\n",
      "Epoch 14/25\n",
      "Train Loss: 0.0137, Train Accuracy: 0.9957\n",
      "Epoch 15/25\n",
      "Train Loss: 0.0127, Train Accuracy: 0.9960\n",
      "Epoch 16/25\n",
      "Train Loss: 0.0124, Train Accuracy: 0.9962\n",
      "Epoch 17/25\n",
      "Train Loss: 0.0123, Train Accuracy: 0.9963\n",
      "Epoch 18/25\n",
      "Train Loss: 0.0112, Train Accuracy: 0.9965\n",
      "Epoch 19/25\n",
      "Train Loss: 0.0106, Train Accuracy: 0.9968\n",
      "Epoch 20/25\n",
      "Train Loss: 0.0107, Train Accuracy: 0.9968\n",
      "Epoch 21/25\n",
      "Train Loss: 0.0099, Train Accuracy: 0.9969\n",
      "Epoch 22/25\n",
      "Train Loss: 0.0099, Train Accuracy: 0.9970\n",
      "Epoch 23/25\n",
      "Train Loss: 0.0096, Train Accuracy: 0.9971\n",
      "Epoch 24/25\n",
      "Train Loss: 0.0090, Train Accuracy: 0.9972\n",
      "Epoch 25/25\n",
      "Train Loss: 0.0091, Train Accuracy: 0.9972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "# def test(model, test_loader, criterion, device):\n",
    "#     model.eval()  \n",
    "    \n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "    \n",
    "#     with torch.no_grad():  \n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "            \n",
    "\n",
    "#             output = model(data)\n",
    "#             loss = criterion(output, target)\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = torch.max(output, 1)\n",
    "            \n",
    "#             total += target.size(0)\n",
    "#             correct += (predicted == target).sum().item()\n",
    "#             all_preds.extend(predicted.cpu().numpy())\n",
    "#             all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "#     epoch_loss = running_loss / len(test_loader)\n",
    "#     epoch_acc = correct / total\n",
    "#     return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5,  \n",
    "    num_heads=8, \n",
    "    num_layers=6  \n",
    ").to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "epochs = 25\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train the model\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    # test_loss, test_acc, preds, labels = test(model, test_loader, criterion, device)\n",
    "    # test_accuracies.append(test_acc)\n",
    "    \n",
    "    # print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    scheduler.step(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = len(train_accuracies)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(num_epochs), train_accuracies[:num_epochs], label='Training Accuracy')\n",
    "# plt.plot(np.arange(num_epochs), test_accuracies[:num_epochs], label='Test Accuracy')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model/cnn_transformer_model_smote.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./model/cnn_transformer_model_smote.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 188)\n"
     ]
    }
   ],
   "source": [
    "test_df = dataframes['mitbih_test']\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_51544\\3926318695.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0        N\n",
      "1        N\n",
      "2        N\n",
      "3        N\n",
      "4        N\n",
      "        ..\n",
      "21887    Q\n",
      "21888    Q\n",
      "21889    Q\n",
      "21890    Q\n",
      "21891    Q\n",
      "Name: 187, Length: 21892, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  test_df.iloc[:, -1] = test_df.iloc[:, -1].replace(labels)\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "test_df.iloc[:, -1] = test_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "x_data = test_df.iloc[:,:187]\n",
    "y_label = test_df.iloc[:,-1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label.values.ravel())\n",
    "\n",
    "\n",
    "\n",
    "X = x_data\n",
    "X_test = np.expand_dims(X, axis=1)  \n",
    "# print(X_test.shape) \n",
    "X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_test_tensor = torch.tensor(y).long()        \n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients during testing\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)         \n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0920, Test Accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "epoch_loss, epoch_acc, all_preds, all_labels = test(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
