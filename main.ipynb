{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A: Deep Learning for ECG Heartbeat Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall evaluate all models on unseen data by using the models which are only trained on the mitbih_train.csv and we do testing on mitbih_test.csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu118\n",
      "CUDA available: True\n",
      "Current CUDA device index: 0\n",
      "CUDA device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current CUDA device index (if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current CUDA device index:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"No CUDA devices found.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = {}\n",
    "directory_path = 'Heartbeat_Dataset'\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        # Remove the .csv extension for the DataFrame name\n",
    "        df_name = os.path.splitext(file)[0]\n",
    "        dataframes[df_name] = pd.read_csv(file_path, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mitbih_test', 'mitbih_train', 'ptbdb_abnormal', 'ptbdb_normal'])\n"
     ]
    }
   ],
   "source": [
    "print(dataframes.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 188)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = dataframes['mitbih_test']\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    " here we map numerical values  of its categories to string labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data = data_df.iloc[:, 2:]\n",
    "# y_label = data_df[['type']]\n",
    "\n",
    "\n",
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "test_df.iloc[:, -1] = test_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "# Get the value counts for the renamed last column\n",
    "# train_counts = test_df.iloc[:, -1].value_counts()\n",
    "# print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = test_df.iloc[:,:187]\n",
    "y_label = test_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187\n",
       "N    18118\n",
       "Q     1608\n",
       "V     1448\n",
       "S      556\n",
       "F      162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 1, 187)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label) \n",
    "\n",
    "X = x_data\n",
    "X_test = np.expand_dims(X, axis=1)  \n",
    "print(X_test.shape) \n",
    "X_test_tensor = torch.tensor(X_test).float()    \n",
    "y_test_tensor = torch.tensor(y).long()        \n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from common_utils import CNN1D\n",
    "\n",
    " \n",
    "\n",
    "model_path = \"./model/cnn_model.pth\"\n",
    "num_classes = len(label_encoder.classes_)\n",
    "loaded_CNNmodel = CNN1D(num_classes).to(device)  \n",
    "loaded_CNNmodel.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for CNN model: 0.9823\n"
     ]
    }
   ],
   "source": [
    "from common_utils import evaluateCNN_model\n",
    "\n",
    "test_accuracy = evaluateCNN_model(x_data, y_label, num_classes, loaded_CNNmodel, batch_size=32, device='cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading transformer modules and constants\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "input_size = 200\n",
    "num_classes = 5\n",
    "num_heads = 5\n",
    "depth = 6\n",
    "max_epochs = 22\n",
    "lr = 1e-4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./heartbeat_Dataset\"\n",
    "from transformer_eval import LitTransformer, LitMITBIH\n",
    "Transformer_model = LitTransformer(input_size, num_classes, num_heads, depth, max_epochs, lr, dropout)\n",
    "datamodule = LitMITBIH( path, batch_size, num_workers, length=input_size)\n",
    "datamodule.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ecg-transformer.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0927aa7102ed49a5953f6da2a37790f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.78797149658203     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11676190793514252    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.78797149658203    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11676190793514252   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 97.78797149658203, 'test_loss': 0.11676190793514252}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"./model/\"\n",
    "ckpt_name = \"ecg-transformer\"\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=os.path.join(save_path, \"checkpoints\"),\n",
    "    filename=ckpt_name,\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_acc',\n",
    "    # monitor='test_acc',\n",
    "    mode='max',\n",
    ")\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=1,\n",
    "\n",
    "                    max_epochs=max_epochs,\n",
    "                    logger=False,\n",
    "                    callbacks=[model_checkpoint]\n",
    "                )\n",
    "\n",
    "print(f\"Loading checkpoint: {ckpt_name}.ckpt\")\n",
    "Transformer_model = Transformer_model.load_from_checkpoint(\n",
    "    os.path.join(save_path, \"checkpoints\", ckpt_name+\".ckpt\")\n",
    ")\n",
    "trainer.test(Transformer_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from common_utils import GRUModel\n",
    "\n",
    "model_path = \"./model/gru_rnn_model.pth\"\n",
    "inputSize = 1\n",
    "hiddenSize = 64\n",
    "numClasses = 5\n",
    "numLayers = 1\n",
    "\n",
    "rnn_model = GRUModel(inputSize, hiddenSize, numLayers, numClasses).to(device)\n",
    "rnn_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (21892, 1, 187)\n",
      "Shape of y: [0. 0. 0. ... 4. 4. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_15904\\970282232.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  RNN_y_test = test_df.iloc[:, -1].replace(reverse_labels).astype(float).values  # Convert labels back to numbers\n"
     ]
    }
   ],
   "source": [
    "# RNN_X_test = np.expand_dims(X, axis=-1) \n",
    "# RNN_X_test_tensor = torch.tensor(RNN_X_test).float()  \n",
    "\n",
    "# # Create DataLoader with updated shape\n",
    "# RNN_test_dataset = TensorDataset(RNN_X_test_tensor, y_test_tensor)\n",
    "# RNN_test_loader = DataLoader(RNN_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "reverse_labels = {v: k for k, v in labels.items()}\n",
    "\n",
    "RNN_X_test = test_df.iloc[:, :-1].values  \n",
    "RNN_y_test = test_df.iloc[:, -1].replace(reverse_labels).astype(float).values  # Convert labels back to numbers\n",
    "\n",
    "RNN_X_test = np.expand_dims(RNN_X_test, axis=1)    \n",
    "\n",
    "print(f\"Shape of X: {RNN_X_test.shape}\")\n",
    "print(f\"Shape of y: {RNN_y_test}\")\n",
    "\n",
    "from common_utils import get_dataloader\n",
    "RNN_test_loader = get_dataloader(RNN_X_test, RNN_y_test, False, batchSize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1, got 187",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m----> 3\u001b[0m RNNLoss, RNNacc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRNN_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRNNLoss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRNNacc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\common_utils.py:251\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, test_loader, device, criterion)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m    250\u001b[0m     X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m    253\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\common_utils.py:99\u001b[0m, in \u001b[0;36mGRUModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru\u001b[38;5;241m.\u001b[39mbidirectional \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m), x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Forward propagate through GRU\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Take the output from the last time step\u001b[39;00m\n\u001b[0;32m    102\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1390\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1386\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m-> 1390\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[0;32m   1393\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1394\u001b[0m         hx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:361\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]\n\u001b[0;32m    360\u001b[0m ):\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:312\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m     )\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1, got 187"
     ]
    }
   ],
   "source": [
    "from common_utils import evaluate\n",
    "\n",
    "RNNLoss, RNNacc = evaluate(rnn_model, RNN_test_loader, device, criterion=nn.CrossEntropyLoss())\n",
    "print(f\"Test Loss: {RNNLoss:.4f} | Test Accuracy: {RNNacc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results obtained from the different models\n",
    "| Model        | Test accuracy |\n",
    "|--------------|---------------|\n",
    "| CNN          | 0.9823        |\n",
    "| Transformers | 0.9779        |\n",
    "| RNN          | 0.8279        |\n",
    "| RNN(LSTM)    | 0.8278        |\n",
    "| RNN(GRU)     | 0.9740        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation of hybrid models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance of individual models, we decided to explore hybrid architectures to leverage the strengths of different models. Consequently, we developed Transformer-CNN and CNN-GRU hybrid models. These hybrid models will be evaluated to assess their effectiveness \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-Transformer hhybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import cnn_transformer_evaluate\n",
    "from CNN_Transformer_hybrid import CNNTransformerHybrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./model/cnn_transformer_model.pth\"\n",
    "\n",
    "CNN_transformer_model = CNNTransformerHybrid(\n",
    "    input_dim=187, \n",
    "    num_classes=5,  \n",
    "    num_heads=8, \n",
    "    num_layers=6  \n",
    ").to(device)\n",
    "\n",
    "CNN_transformer_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./model/cnn_transformer_model.pth\n",
      "Test Loss: 0.0666 | Test Accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "epoch_loss, epoch_acc, all_preds, all_labels = cnn_transformer_evaluate(CNN_transformer_model, test_loader, criterion, device)\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "print(f\"Test Loss: {epoch_loss:.4f} | Test Accuracy: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model run on augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Loading model from: ./model/cnn_transformer_model_augment.pth\n",
      "Test Loss: 0.0671 | Test Accuracy: 0.9855\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./model/cnn_transformer_model_augment.pth\"\n",
    "\n",
    "CNN_transformer_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "cnn_transformer_augment_epoch_loss, cnn_transformer_augment_epoch_acc, cnn_transformer_augment_all_preds, cnn_transformer_augment_all_labels = cnn_transformer_evaluate(CNN_transformer_model, test_loader, criterion, device)\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "print(f\"Test Loss: {cnn_transformer_augment_epoch_loss:.4f} | Test Accuracy: {cnn_transformer_augment_epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model run on smote dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Loading model from: ./model/cnn_transformer_model_smote.pth\n",
      "Test Loss: 0.0920 | Test Accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"./model/cnn_transformer_model_smote.pth\"\n",
    "\n",
    "CNN_transformer_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "cnn_transformer_smote_epoch_loss, cnn_transformer_smote_epoch_acc, cnn_transformer_smote_all_preds, cnn_transformer_smote_all_labels = cnn_transformer_evaluate(CNN_transformer_model, test_loader, criterion, device)\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "print(f\"Test Loss: {cnn_transformer_smote_epoch_loss:.4f} | Test Accuracy: {cnn_transformer_smote_epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(cnn_transformer_augment_all_labels, cnn_transformer_augment_all_preds, labels=[1, 3, 4, 0, 2])\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['N', 'S', 'V', 'F', 'Q'])\n",
    "disp.plot( values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.992009</td>\n",
       "      <td>0.993542</td>\n",
       "      <td>0.992775</td>\n",
       "      <td>18118.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>556.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.957182</td>\n",
       "      <td>0.966864</td>\n",
       "      <td>1448.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>162.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0.993155</td>\n",
       "      <td>1608.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.98552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.904095</td>\n",
       "      <td>0.927581</td>\n",
       "      <td>0.912580</td>\n",
       "      <td>21892.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.985599</td>\n",
       "      <td>21892.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "N              0.992009  0.993542  0.992775  18118.00000\n",
       "S              0.881890  0.805755  0.842105    556.00000\n",
       "V              0.976744  0.957182  0.966864   1448.00000\n",
       "F              0.676056  0.888889  0.768000    162.00000\n",
       "Q              0.993773  0.992537  0.993155   1608.00000\n",
       "accuracy       0.985520  0.985520  0.985520      0.98552\n",
       "macro avg      0.904095  0.927581  0.912580  21892.00000\n",
       "weighted avg   0.985994  0.985520  0.985599  21892.00000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds, truths = test(CNN_transformer_model, test_loader, device)\n",
    "# report = classification_report(truths, preds, labels=[0.0, 1.0, 2.0, 3.0, 4.0], target_names=['N', 'S', 'V', 'S', 'Q'], output_dict=True)\n",
    "# conf_matrix = confusion_matrix(truths, preds, labels=[0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "report = classification_report(cnn_transformer_augment_all_labels, cnn_transformer_augment_all_preds, labels=[1, 3, 4, 0, 2], target_names=['N', 'S', 'V', 'F', 'Q'], output_dict=True)\n",
    "\n",
    "# Convert the report dictionary to a DataFrame and display\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Loss: 0.0666 | Test Accuracy: 0.9850 \\\n",
    "Test Loss: 0.0714 | Test Accuracy: 0.9857 \\\n",
    "Test Loss: 0.1000 | Test Accuracy: 0.9744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import CNN_GRU\n",
    "CNN_GRU_model = CNN_GRU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model/CNN_GRU_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/CNN_GRU_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m CNN_GRU_model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m CNNGRULoss, CNNGRUacc \u001b[38;5;241m=\u001b[39m evaluate(CNN_GRU_model, test_loader, device, criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCNNGRULoss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCNNGRUacc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model/CNN_GRU_model.pth'"
     ]
    }
   ],
   "source": [
    "model_path = './model/CNN_GRU_model.pth'\n",
    "CNN_GRU_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "CNNGRULoss, CNNGRUacc = evaluate(CNN_GRU_model, test_loader, device, criterion=nn.CrossEntropyLoss())\n",
    "print(f\"Test Loss: {CNNGRULoss:.4f} | Test Accuracy: {CNNGRUacc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
