{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A: Deep Learning for ECG Heartbeat Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall evaluate all models on unseen data by training only on the mitbih_train.csv and testing on mitbih_test.csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu118\n",
      "CUDA available: True\n",
      "Current CUDA device index: 0\n",
      "CUDA device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Get current CUDA device index (if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current CUDA device index:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"No CUDA devices found.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = {}\n",
    "directory_path = 'Heartbeat_Dataset'\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        # Remove the .csv extension for the DataFrame name\n",
    "        df_name = os.path.splitext(file)[0]\n",
    "        dataframes[df_name] = pd.read_csv(file_path, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mitbih_test', 'mitbih_train', 'ptbdb_abnormal', 'ptbdb_normal'])\n"
     ]
    }
   ],
   "source": [
    "print(dataframes.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 188)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = dataframes['mitbih_test']\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    " here we map numerical values  of its categories to string labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "N    18118\n",
      "Q     1608\n",
      "V     1448\n",
      "S      556\n",
      "F      162\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randa\\AppData\\Local\\Temp\\ipykernel_65632\\251356151.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0        N\n",
      "1        N\n",
      "2        N\n",
      "3        N\n",
      "4        N\n",
      "        ..\n",
      "21887    Q\n",
      "21888    Q\n",
      "21889    Q\n",
      "21890    Q\n",
      "21891    Q\n",
      "Name: 187, Length: 21892, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  test_df.iloc[:, -1] = test_df.iloc[:, -1].replace(labels)\n"
     ]
    }
   ],
   "source": [
    "# x_data = data_df.iloc[:, 2:]\n",
    "# y_label = data_df[['type']]\n",
    "\n",
    "\n",
    "labels = {\n",
    "    0.0: \"N\",\n",
    "    1.0: \"S\",\n",
    "    2.0: \"V\",\n",
    "    3.0: \"F\",\n",
    "    4.0: \"Q\"\n",
    "}\n",
    "\n",
    "test_df.iloc[:, -1] = test_df.iloc[:, -1].replace(labels)\n",
    "\n",
    "# Now get the value counts for the renamed last column\n",
    "train_counts = test_df.iloc[:, -1].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = test_df.iloc[:,:187]\n",
    "y_label = test_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187\n",
       "N    18118\n",
       "Q     1608\n",
       "V     1448\n",
       "S      556\n",
       "F      162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from common_utils import CNN1D\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_label)  # Encode labels without replacement\n",
    "\n",
    "model_path = \"./model/cnn_model.pth\"\n",
    "num_classes = len(label_encoder.classes_)\n",
    "loaded_CNNmodel = CNN1D(num_classes).to(device)  # Reinitialize model with the same architecture\n",
    "loaded_CNNmodel.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for CNN model: 0.9823\n"
     ]
    }
   ],
   "source": [
    "from common_utils import evaluateCNN_model\n",
    "\n",
    "test_accuracy = evaluateCNN_model(x_data, y_label, num_classes, loaded_CNNmodel, batch_size=32, device='cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading transformer modules and constants\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "input_size = 200\n",
    "num_classes = 5\n",
    "num_heads = 5\n",
    "depth = 6\n",
    "max_epochs = 22\n",
    "lr = 1e-4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./heartbeat_Dataset\"\n",
    "from common_utils import LitTransformer, LitMITBIH\n",
    "model = LitTransformer(input_size, num_classes, num_heads, depth, max_epochs, lr, dropout)\n",
    "datamodule = LitMITBIH( path, batch_size, num_workers, length=input_size)\n",
    "datamodule.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ecg-transformer.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\randa\\OneDrive\\Documents\\GitHub\\Neural-Networks-Project\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9bb3f786054fbc8b836f03aad12d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.78797149658203     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11676190793514252    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.78797149658203    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11676190793514252   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 97.78797149658203, 'test_loss': 0.11676190793514252}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"./model/\"\n",
    "ckpt_name = \"ecg-transformer\"\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=os.path.join(save_path, \"checkpoints\"),\n",
    "    filename=ckpt_name,\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_acc',\n",
    "    # monitor='test_acc',\n",
    "    mode='max',\n",
    ")\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=1,\n",
    "\n",
    "                    max_epochs=max_epochs,\n",
    "                    logger=False,\n",
    "                    callbacks=[model_checkpoint]\n",
    "                )\n",
    "\n",
    "print(f\"Loading checkpoint: {ckpt_name}.ckpt\")\n",
    "model = model.load_from_checkpoint(\n",
    "    os.path.join(save_path, \"checkpoints\", ckpt_name+\".ckpt\")\n",
    ")\n",
    "trainer.test(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNNModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model/simple_rnn_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m rnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mRNNModel\u001b[49m(inputSize, hiddenSize, numLayers, numClasses)\n\u001b[0;32m      4\u001b[0m rnn_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RNNModel' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = \"./model/simple_rnn_model.pth\"\n",
    "\n",
    "rnn_model = RNNModel(inputSize, hiddenSize, numLayers, numClasses)\n",
    "rnn_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results obtained from the different models\n",
    "| Model        | Test accuracy |\n",
    "|--------------|---------------|\n",
    "| CNN          | 0.9823        |\n",
    "| Transformers | 0.9779        |\n",
    "| RNN          | 0.8279        |\n",
    "| RNN(LSTM)    | 0.8278        |\n",
    "| RNN(GRU)     | 0.9740        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
